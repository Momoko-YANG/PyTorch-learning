{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5357861f",
   "metadata": {},
   "source": [
    "#### PyTorch基础：审计网络包`nn`和优化器`optm`\n",
    "\n",
    "`torch.nn`是专门为神经网络设计的模块化接口。`nn`构建于`Autograd`之上，可用来定义和运行神经网络。这里我们主要介绍的是几个一些常用的类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91cdc299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd97199",
   "metadata": {},
   "source": [
    "除了`nn`别名以外，我们还引用了`nn.functional`，这个包中包含了神经网络中使用的一些常用函数，这些函数的特点是，不具有可学习的参数(如`ReLU`，`pool`，`DropOut`等)，这些函数可以放在构造函数中，也可以不放。这里建议不放。\n",
    "\n",
    "一般情况下我们会将`nn.functional`设置为大写的F，这样缩写方便调用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83a5c11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b64109f",
   "metadata": {},
   "source": [
    "#### 定义一个网络\n",
    "\n",
    "PyTorch中已经为我们准备好了线程的网络模型，只要继承`nn.Module`，并实现它的`forward`方法，PyTorch会根据autograd，自动实现`backward`函数，在`forward`函数中可使用任何tensor支持的函数，还可以使用`if`,`for`循环，`print`,`log`等Python语法，写法和标准的Python写法一致。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "497221b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=1350, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3) # 输入通道1，输出通道6，卷积核3x3\n",
    "        self.fc1 = nn.Linear(1350, 10) # 全连接层，输入1350，输出10\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(x.size())\n",
    "        # 卷积 -> 激活 -> 池化 \n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        print(x.size())\n",
    "\n",
    "        x = F.max_pool2d(x, (2, 2))\n",
    "        x = F.relu(x)\n",
    "\n",
    "        print(x.size())\n",
    "\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        print(x.size())\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4eb19bc",
   "metadata": {},
   "source": [
    "网络的可学习通过`net.parameters()`返回"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dee614c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[ 0.2173,  0.0440,  0.2857],\n",
      "          [ 0.2057, -0.0692,  0.2753],\n",
      "          [-0.1319, -0.0223, -0.0573]]],\n",
      "\n",
      "\n",
      "        [[[-0.2166, -0.2418, -0.2306],\n",
      "          [ 0.2657,  0.0525, -0.1871],\n",
      "          [ 0.0207,  0.1095, -0.1228]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1967,  0.1939,  0.3002],\n",
      "          [-0.2791,  0.2969,  0.2089],\n",
      "          [ 0.0929, -0.0466,  0.1772]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1503,  0.0284,  0.0694],\n",
      "          [ 0.1241, -0.0491,  0.2438],\n",
      "          [ 0.0805,  0.0167,  0.1870]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3273,  0.0702,  0.2784],\n",
      "          [ 0.3303,  0.0772,  0.0736],\n",
      "          [-0.2278,  0.2703, -0.0339]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2486,  0.1426, -0.1970],\n",
      "          [-0.1535, -0.0873,  0.0620],\n",
      "          [-0.1726, -0.2448,  0.3244]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.3050, 0.2006, 0.1481, 0.1062, 0.1506, 0.2509], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0060, -0.0162, -0.0256,  ..., -0.0252, -0.0137,  0.0007],\n",
      "        [ 0.0196,  0.0244, -0.0196,  ..., -0.0020, -0.0012,  0.0059],\n",
      "        [-0.0178, -0.0038, -0.0144,  ..., -0.0088,  0.0058, -0.0086],\n",
      "        ...,\n",
      "        [-0.0230,  0.0156, -0.0130,  ..., -0.0060, -0.0058,  0.0196],\n",
      "        [ 0.0015,  0.0176, -0.0231,  ..., -0.0241, -0.0264,  0.0078],\n",
      "        [-0.0033, -0.0252,  0.0218,  ..., -0.0169,  0.0158, -0.0003]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0107, -0.0174,  0.0205, -0.0238,  0.0213,  0.0260, -0.0048, -0.0133,\n",
      "         0.0029,  0.0233], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for parameters in net.parameters():\n",
    "    print(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18242aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight : torch.Size([6, 1, 3, 3])\n",
      "conv1.bias : torch.Size([6])\n",
      "fc1.weight : torch.Size([10, 1350])\n",
      "fc1.bias : torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name, parameters in net.named_parameters():\n",
    "    print(name, ':', parameters.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cedfe1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 32, 32])\n",
      "torch.Size([1, 6, 30, 30])\n",
      "torch.Size([1, 6, 15, 15])\n",
      "torch.Size([1, 1350])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 32, 32) # batch_size=1, channel=1, height=32, width=32\n",
    "out = net(input)  \n",
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fab43116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 32, 32])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6c5336",
   "metadata": {},
   "source": [
    "在反向传播前，先要将所有的参数梯度清零"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9dbf2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad() \n",
    "out.backward(torch.randn(1,10))  #反向传播的实现是PyTorch自动实现的，我们只需要调用这个函数即可"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d907b732",
   "metadata": {},
   "source": [
    "**注意**: `torch.nn`只支持mini-batches，不支持一次只输入一个样本，即以此必须是一个batch。\n",
    "\n",
    "也就是说，就算我们输入一个样本，也会对样本进行分批，所以，所有的输入都会增加一个维度，我们对比下刚才的input，`nn`中定义为3维，但是我们人工创建时多增加了一个维度，变为了4维，最前面的1即为batch-size。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfb0932",
   "metadata": {},
   "source": [
    "#### 损失函数\n",
    "在`nn`中PyTorch还预制了常用的损失函数，下面我们用MSELoss用来计算均方误差。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64419e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.068767547607422\n"
     ]
    }
   ],
   "source": [
    "y = torch.arange(0, 10).view(1, 10).float() \n",
    "criterion = nn.MSELoss()\n",
    "loss = criterion(out, y)\n",
    "\n",
    "# loss是个scalar，我们可以直接用item获取到他的python类型的数值\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1aa5e8c",
   "metadata": {},
   "source": [
    "#### 优化器\n",
    "\n",
    "在反向传播计算完所有参数的梯度后，还需要使用优化方法来更新网络的权重和参数，例如随机梯度下降法（SGD）的更新策略如下：\n",
    "\n",
    "`weight = weight - learning_rate * gradient`\n",
    "\n",
    "在`torch.optim`中实现大多数的优化方法，例如`RMSProp`,`Adam`,`SGD`等，下面我们使用SGD做个简单的样例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7d79146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 32, 32])\n",
      "torch.Size([1, 6, 30, 30])\n",
      "torch.Size([1, 6, 15, 15])\n",
      "torch.Size([1, 1350])\n"
     ]
    }
   ],
   "source": [
    "import torch.optim\n",
    "\n",
    "out = net(input)\n",
    "criterion = nn.MSELoss()\n",
    "loss = criterion(out, y)\n",
    "\n",
    "# 新建一个优化器，SGD只需要调整的参数和学习率\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr = 0.01)\n",
    "\n",
    "# 先清零梯度（与net.zero_grad()效果一样）\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "\n",
    "optimizer.step()  # 更新所有参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b47bbf",
   "metadata": {},
   "source": [
    "这样，神经网络的数据的一个完整的传播就已经通过PyTorch实现了，下面一章将介绍PyTorch提供的数据加载和处理工具，使用这些工具可以方便地处理所需要地数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c710a2e",
   "metadata": {},
   "source": [
    "#### PyTorch基础：数据的加载和预处理\n",
    "\n",
    "PyTorch通过`torch.utils.data`对一般常用的数据加载进行了封装，可以很容易地实现多线程数据预读和批量加载。并且`torchvision`已经预先实现了常用图像数据集，包括前面使用过的`CIFAR-10`,`ImageNet`,`COCO`,`MINIST`,`LSUN`等数据集，可以通过`torchvision.datasets`方便调用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d5f9bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4bffa5",
   "metadata": {},
   "source": [
    "#### Dataset\n",
    "\n",
    "`Dataset`是一个抽象类，为了能够方便地读取，需要将使用的数据包装为Dataset类。自定义的Dataset需要继承它并且实现两个成员方法：\n",
    "\n",
    "1. `__getitem__()`该方法定义用索引（`0`到`len(self)`）获取一条数据或一个样本\n",
    "2. `__len__()`该方法返回数据集的总长度\n",
    "\n",
    "下面我们使用kaggle上的一个竞赛bluebook for bulldozers自定义一个数据集，为了方便介绍，我们使用里面的数据字典来做说明（因为条数少）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69f982e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "056cec16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BulldozerDataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.df.iloc[idx].SalePrice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb893f85",
   "metadata": {},
   "source": [
    "至此，我们的数据集已经定义完成了，我们可以实例化一个对象访问它"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82b314ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_demo = BulldozerDataset('data/median_benchmark.csv') # 修改为实际路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad66d899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11573"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds_demo)  # #实现了 __len__ 方法所以可以直接使用len获取数据总数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b65ba6fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(24000.0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_demo[0]  #用索引可以直接访问对应的数据，对应 __getitem__ 方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45021452",
   "metadata": {},
   "source": [
    "自定义的数据集已经创建好了，下面我们使用官方提供的数据载入器读取数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f22908",
   "metadata": {},
   "source": [
    "#### Dataloader\n",
    "\n",
    "DataLoader为我们提供了对Dataset的读取操作，常用参数有：`batch_size`（每个batch的大小），`shuffle`（是否进行shuffle操作），`num_workers`（加载数据的时候使用几个子进程）。下面做一个简单的操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f2a1bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = torch.utils.data.DataLoader(ds_demo, batch_size = 4, shuffle = True, num_workers = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5359c321",
   "metadata": {},
   "source": [
    "DataLoader返回的是一个可迭代对象，我们可以使用迭代器分次获取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fad12645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([24000., 24000., 24000., 24000.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "idata = iter(dl)\n",
    "print(next(idata))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f087509d",
   "metadata": {},
   "source": [
    "常见的用法是使用for循环对其进行遍历："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9880f877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([24000., 24000., 24000., 24000.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(dl):\n",
    "    print(i, data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75eb8a22",
   "metadata": {},
   "source": [
    "我们已经可以通过`dataset`定义数据集，并使用`Dataloder`载入和遍历数据集，除了这些以外，PyTorch还能提供能`torcvison`的计算机视觉扩展包，里边封装了\n",
    "\n",
    "- `torchvision`包\n",
    "- `torchvision.datasets`：`torchvision.datasets`可以理解为PyTorch团队自定义的dataset，这些dataset帮我们提前处理好了很多的图片数据集，我们拿来就可以直接使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83430c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, ), (0.5, ))\n",
    "\n",
    "])\n",
    "trainset = datasets.MNIST(root = './data', \n",
    "                           train = True,  # 表示是否加载数据库的训练集，false的时候加载测试集\n",
    "                           download = True,  #是否从网上下载数据集\n",
    "                           transform = None) # 数据预处理操作"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516664a4",
   "metadata": {},
   "source": [
    "- `torchvision.models`不仅提供了常用图片数据集，还提供了训练好的模型，可以加载之后直接使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "144a9ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/momokoyang/Library/Python/3.9/lib/python/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/momokoyang/Library/Python/3.9/lib/python/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "0.3%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /Users/momokoyang/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "resnet18 = models.resnet18(pretrained = True) #加载预训练的ResNet18模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa9ab74",
   "metadata": {},
   "source": [
    "- `torchvision.transforms`模块提供了一般的图像转换操作类，用作数据处理和数据增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa67fc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms as transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),  #随机裁剪32x32的图片，边界填充4个像素\n",
    "    transforms.RandomHorizontalFlip(),  #随机水平翻转图片\n",
    "    transforms.RandomRotation((-45, 45)),  #随机旋转图片，旋转角度在-45到45度之间\n",
    "    transforms.ToTensor(),  #将图片转换为Tensor格式\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))  #R,G,B每层的归一化用到的均值和方差\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04960c0",
   "metadata": {},
   "source": [
    "(0.485, 0.456, 0.406), (0.2023, 0.1994, 0.2010) 这几个数字是什么意思？\n",
    "\n",
    "官方的这个帖子有详细的说明: https://discuss.pytorch.org/t/normalization-in-the-mnist-example/457/21 这些都是根据ImageNet训练的归一化参数，可以直接使用，我们认为这个是固定值就可以"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
