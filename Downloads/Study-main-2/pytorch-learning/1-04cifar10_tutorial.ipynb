{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0ab7172",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db29500b",
   "metadata": {},
   "source": [
    "#### 训练一个分类器\n",
    "\n",
    "##### 关于数据\n",
    "\n",
    "一般情况下处理图像，文本，音频和视频数据时，可以使用标准的Python包来加载数据到一个numpy数组中。然后把这个数组转换成`torch.*Tensor` 。\n",
    "\n",
    "- 图像可以使用Pillow，OpenCV\n",
    "- 音频可以使用scipy，librosa\n",
    "- 文本可以使用原始Python和Cython来加载，或者使用NLTK或者SpaCy处理\n",
    "\n",
    "特别的，对于图像任务，我们创建了一个包`torchvision`，它包含了处理一些基本图像数据集的方法。这些数据集包括Imagenet，CIFAR10，MINIST等。除了数据加载以外，`torchvision`还包含了图像转换器，`torchvision.datasets`和`torch.utils.data.DataLoader`。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e69c47e",
   "metadata": {},
   "source": [
    "##### 训练一个图像分类器\n",
    "依次按照下列顺序进行：\n",
    "1. 使用`torchvision`加载和归一化CIFAR10训练集和测试集\n",
    "2. 定义一个卷积神经网络\n",
    "3. 定义损失函数\n",
    "4. 在训练集上训练网络\n",
    "5. 在测试集上测试网络\n",
    "6. 读取和归一化CIFAR10\n",
    "\n",
    "使用`torchvision`可以非常容易地加载CIFAR10。\n",
    "\n",
    "CIFAR-10的图像都是 3x32x32大小的，即，3颜色通道，32x32像素。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03aed842",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cf4351",
   "metadata": {},
   "source": [
    "`torchvision`的输出是[0,1]的PILImage图像，我们把它转换为归一化范围为[-1,1]的张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a3c1a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ") # 定义一个转换器，将PIL图像转换为张量，并归一化\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train = True,\n",
    "                                        download=True, transform=transform)  # 下载训练集\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = 4,\n",
    "                                          shuffle = True, num_workers = 2)  # 创建训练集的数据加载器\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False,\n",
    "                                       download = True, transform = transform)  # 下载测试集\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = 4,\n",
    "                                         shuffle = False, num_workers = 2)  # 创建测试集的数据加载器\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')  # 定义类别名称"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006065de",
   "metadata": {},
   "source": [
    "我们展示一些训练图像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9ed8eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'img'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(dataiter)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# 显示图像\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_grid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# 打印标签\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%5s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m classes[labels[j]] \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m4\u001b[39m))) \n",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m, in \u001b[0;36mimshow\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m      6\u001b[0m img \u001b[38;5;241m=\u001b[39m img \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.5\u001b[39m  \u001b[38;5;66;03m# 反归一化\u001b[39;00m\n\u001b[1;32m      7\u001b[0m npimg \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m----> 8\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(np\u001b[38;5;241m.\u001b[39mtranspose(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg\u001b[49m, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m)))\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/numpy/__init__.py:410\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchar\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchar\u001b[39;00m\n\u001b[1;32m    408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m char\u001b[38;5;241m.\u001b[39mchararray\n\u001b[0;32m--> 410\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;18m__name__\u001b[39m, attr))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'img'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 显示图像的函数\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # 反归一化\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(np.img, (1, 2, 0)))\n",
    "\n",
    "\n",
    "# 获取一些随机训练图像\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter) \n",
    "\n",
    "# 显示图像\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "# 打印标签\n",
    "print(''.join('%5s' % classes[labels[j]] for j in range(4))) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de3a449",
   "metadata": {},
   "source": [
    "2. 定义一个卷积神经网络\n",
    "\n",
    "从之前的神经网络一节赋值神经网络代码，并修改为输入3通道图像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4bf764",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5) # 输入通道数3，输出通道数6，卷积核大小5x5\n",
    "        self.pool = nn.MaxPool2d(2, 2)  # 池化层，窗口大小2x2\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5) # 输入通道数6，输出通道数16，卷积核大小5x5\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120) # 全连接层，输入特征数16*5*5，输出特征数120\n",
    "        self.fc2 = nn.Linear(120, 84)  # 全连接层，输入特征数120，输出特征数84\n",
    "        self.fc3 = nn.Linear(84, 10)   # 全连接层，输入特征数84，输出特征数10\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # 卷积层1 + ReLU激活 + 池化\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # 卷积层2 + ReLU激活 + 池化\n",
    "        x = x.view(-1, 16 * 5 * 5)            # 展平张量\n",
    "        x = F.relu(self.fc1(x))               # 全连接层1 + ReLU激活\n",
    "        x = F.relu(self.fc2(x))               # 全连接层2 + ReLU激活\n",
    "        x = self.fc3(x)                       # 全连接层3\n",
    "        return x\n",
    "\n",
    "net = Net() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6825d14",
   "metadata": {},
   "source": [
    "3. 定义损失函数和优化器\n",
    "\n",
    "我们使用交叉熵作为损失函数，使用带动量的随机梯度下降。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43d95f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # 交叉熵损失函数\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) # 带动量的随机梯度下降优化器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cee0b28",
   "metadata": {},
   "source": [
    "4. 训练网络\n",
    "\n",
    "我们只需要在数据迭代器上循环，将数据输入给网络，并优化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74027991",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2):  # 遍历数据集两次\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # 获取输入数据\n",
    "        inputs, labels = data\n",
    "\n",
    "        # 将梯度缓存清零\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 正向传播，反向传播，优化\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 打印统计信息\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # 每2000个小批量打印一次\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc40ba4",
   "metadata": {},
   "source": [
    "5. 在测试集上测试网络\n",
    "\n",
    "我们在整个训练集上进行了2次训练，但是我们需要检查网络是否从数据集中学到有用的东西。通过预测神经网络输出的类别标签与实际情况标签进行对比来进行检测。如果预测正确，我们把该样本添加到正确预测列表。\n",
    "\n",
    "第一步，显示测试集中的图片并熟悉图片内容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdb871c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# 显示测试图像\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# 打印真实标签\n",
    "print('GroundTruth:', ''.join('%5s' % classes[labels[j] ]for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e9bbcf",
   "metadata": {},
   "source": [
    "查看神经网络如何判定图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3268747d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m outputs = \u001b[43mnet\u001b[49m(images)\n",
      "\u001b[31mNameError\u001b[39m: name 'net' is not defined"
     ]
    }
   ],
   "source": [
    "outputs = net(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bb0c16",
   "metadata": {},
   "source": [
    "输出的是10个标签的能量。一个类别的能量越大，神经网络越认为它是这个类别。所以让我们得到最高能量的标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8eb3111",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted = torch.max(outputs, 1) # 获取每行的最大值及其索引\n",
    "\n",
    "print('Predicted:', ' '.join('%5s' % classes[predicted[j]] for j in range(4)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbe834b",
   "metadata": {},
   "source": [
    "接下来查看网络在测试集上的结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a58231",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654fac4b",
   "metadata": {},
   "source": [
    " 在识别不同的类时的结果？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26e0071",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data       # 获取数据\n",
    "        outputs = net(images) # 获取网络输出\n",
    "        _, predicted = torch.max(outputs, 1) # 获取预测结果\n",
    "        c = (predicted == labels).squeeze() # 比较预测结果与真实标签\n",
    "        for i in range(4):\n",
    "            label = labels[i] # 获取真实标签\n",
    "            class_correct[label] += c[i].item()     # 累加正确预测数\n",
    "            class_total[label] += 1               # 累加总数\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efc4d3e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd30f96a",
   "metadata": {},
   "source": [
    "#### 在GPU上训练\n",
    "\n",
    "这个操作会递归遍历所有模块，并将其参数和缓冲区转换为CUDA张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b4f32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd40f288",
   "metadata": {},
   "source": [
    "假定`device`是CUDA设备\n",
    "\n",
    "然后将这些方法递归遍历所有模块并将模块的参数和缓冲区转换为CUDA张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d538a8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mnet\u001b[49m.to(device)\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# input, targets 和 images 也需要被转换到相同的设备上\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'net' is not defined"
     ]
    }
   ],
   "source": [
    "net.to(device)\n",
    "\n",
    "# input, targets 和 images 也需要被转换到相同的设备上\n",
    "inputs, labels = inputs.to(device), labels.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b255daff",
   "metadata": {},
   "source": [
    "多GPU训练\n",
    "\n",
    "参考下一节"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4000df96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
